experiment:
  name: attention_v2
  save_dir: /ix/djishnu/Aaron_F/ES_interact/Results/substrate_attention

paths:
  train_pairs: /ix/djishnu/Aaron_F/ES_interact/Results/training_data/1_to_10_ratio/out_files/pos_neg_pairs.csv
  kinase_embeddings: /ix/djishnu/Aaron_F/ES_interact/Results/ser_thr_kinases/out_files/kinase_esm2_embeddings.pkl

data:
  train_ratio: 0.7
  val_ratio: 0.15
  test_ratio: 0.15
  random_seed: 42

model:
  num_groups: 5
  substrate_embedding_dim: 64
  kinase_dim: 1280
  attention_heads: 4
  hidden_dim: 256
  dropout: 0.1

training:
  batch_size: 32
  learning_rate: 0.0001
  num_epochs: 50
  patience: 10
